{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80ee1c63",
   "metadata": {},
   "source": [
    "# EEG Motor Movement/Imagery Classification Using Random Forest and Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd86da42",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f635bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from scipy.signal import detrend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d67dbd7",
   "metadata": {},
   "source": [
    "### Getting .env variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0e848b",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "INPUT_DIR = os.getenv(\"INPUT_DIR\", \"./data/raw\")\n",
    "OUTPUT_DIR = os.getenv(\"OUTPUT_DIR\", \"./result\")\n",
    "\n",
    "SFREQ = int(os.getenv(\"SFREQ\", 160))\n",
    "WINDOW_SEC = float(os.getenv(\"WINDOW_SEC\", 2))\n",
    "OVERLAP = float(os.getenv(\"OVERLAP\", 0.5))\n",
    "\n",
    "DEBUG = os.getenv(\"DEBUG\", \"1\").strip().lower() in {\"1\", \"true\", \"yes\", \"y\"}\n",
    "# DEBUG = False\n",
    "print(f\"DEBUGGING is {'ON' if DEBUG else 'OFF'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebcad09",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_samples = int(SFREQ * WINDOW_SEC)\n",
    "print(f\"Window samples: {window_samples}\")\n",
    "\n",
    "records_file = os.path.join(INPUT_DIR, \"RECORDS\")\n",
    "print(f\"Records file: {records_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1099b7e",
   "metadata": {},
   "source": [
    "## 1. Data Preparation\n",
    "\n",
    "This data set consists of over 1500 one- and two-minute EEG recordings, obtained from 109 volunteers, as described below.\n",
    "\n",
    "Subjects performed different motor/imagery tasks while 64-channel EEG were recorded using the BCI2000 system (http://www.bci2000.org). \n",
    "\n",
    "The experimental runs were:\n",
    "1. Baseline, eyes open\n",
    "2. Baseline, eyes closed\n",
    "3. Task 1 (open and close left or right fist)\n",
    "4. Task 2 (imagine opening and closing left or right fist)\n",
    "5. Task 3 (open and close both fists or both feet)\n",
    "6. Task 4 (imagine opening and closing both fists or both feet)\n",
    "7. Task 1\n",
    "8. Task 2\n",
    "9. Task 3\n",
    "10. Task 4\n",
    "11. Task 1\n",
    "12. Task 2\n",
    "13. Task 3\n",
    "14. Task 4\n",
    "\n",
    "Each annotation includes one of three codes (**T0**, **T1**, or **T2**):\n",
    "- **T0** corresponds to rest\n",
    "- **T1** corresponds to onset of motion (real or imagined) of\n",
    "    the left fist (in runs 3, 4, 7, 8, 11, and 12)\n",
    "    both fists (in runs 5, 6, 9, 10, 13, and 14)\n",
    "- **T2** corresponds to onset of motion (real or imagined) of\n",
    "    the right fist (in runs 3, 4, 7, 8, 11, and 12)\n",
    "    both feet (in runs 5, 6, 9, 10, 13, and 14)\n",
    "\n",
    "### 1.1. Loading RECORDS file and verifying EDF files' existence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f82d41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(records_file, \"r\") as f:\n",
    "    records = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "print(f\"Number of RECORDS entries: {len(records)}\")\n",
    "for r in records[:4]:\n",
    "    print(\" \", r)\n",
    "print(\"  ...\\n \",records[-1])\n",
    "\n",
    "edf_paths = []\n",
    "missing = []\n",
    "\n",
    "for rel in records:\n",
    "    p = os.path.join(INPUT_DIR, rel)\n",
    "    if os.path.exists(p):\n",
    "        edf_paths.append(p)\n",
    "    else:\n",
    "        missing.append(p)\n",
    "\n",
    "print(f\"\\nResolved EDF files: {len(edf_paths)}\")\n",
    "print(f\"Missing EDF files: {len(missing)}\")\n",
    "\n",
    "if missing:\n",
    "    print(\"Example missing path:\", missing[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6255835",
   "metadata": {},
   "source": [
    "### 1.2. Testing [first] EDF file loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fc24d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    test_edf = edf_paths[0]\n",
    "    print(\"Testing EDF:\", test_edf)\n",
    "\n",
    "    raw = mne.io.read_raw_edf(test_edf, preload=False, verbose=False)\n",
    "\n",
    "    print(\"\\n--- EDF INFO ---\")\n",
    "    print(\"Channels:\", len(raw.ch_names))\n",
    "    print(\"Sampling freq:\", raw.info[\"sfreq\"])\n",
    "    print(\"Duration (sec):\", raw.times[-1])\n",
    "    print(\"First 10 channels:\", raw.ch_names[:10])\n",
    "\n",
    "    assert len(raw.ch_names) >= 64, \"Expected ~64 EEG channels\"\n",
    "    assert abs(raw.info[\"sfreq\"] - SFREQ) < 1e-3, \"Sampling frequency mismatch\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c8eca8",
   "metadata": {},
   "source": [
    "### 1.3. Preprocessing All EDF Files and Saving Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9c2f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_summarize(edf_path: Path):\n",
    "    raw = mne.io.read_raw_edf(edf_path, preload=False, verbose=False)\n",
    "    descs = sorted(map(str, set(raw.annotations.description))) if raw.annotations is not None else []\n",
    "    print(\"\\n===\", edf_path.name, \"===\")\n",
    "    print(\"sfreq:\", raw.info[\"sfreq\"], \"| duration:\", raw.times[-1], \"sec | ch:\", len(raw.ch_names))\n",
    "    print(\"Annotations count:\", len(raw.annotations))\n",
    "    print(\"Unique descriptions:\", descs)\n",
    "\n",
    "    events, event_id = mne.events_from_annotations(raw, verbose=False)\n",
    "    event_id = {str(k): v for k, v in event_id.items()}\n",
    "    print(\"event_id:\", event_id)\n",
    "    print(\"n_events:\", len(events))\n",
    "    print(\"first events:\", events[:10])\n",
    "    return raw, events, event_id\n",
    "\n",
    "if DEBUG:\n",
    "    raw, events, event_id = load_and_summarize(Path(test_edf))\n",
    "else:\n",
    "    for edf in edf_paths:\n",
    "        raw, events, event_id = load_and_summarize(Path(edf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21cc441",
   "metadata": {},
   "source": [
    "### 1.4. Imaging vs. Execution Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a19860",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_MOTOR_MOVE = {3, 5, 7, 9, 11, 13}\n",
    "RUN_MOTOR_IMAG = {4, 6, 8, 10, 12, 14}\n",
    "\n",
    "def run_id_from_filename(fname: str):\n",
    "    # \"S001R03.edf\" -> 3\n",
    "    return int(fname.split(\"R\")[1].split(\".\")[0])\n",
    "\n",
    "def get_exec_imag_label(run_id: int):\n",
    "    # 0 = executed, 1 = imagined\n",
    "    if run_id in RUN_MOTOR_MOVE:\n",
    "        return 0\n",
    "    if run_id in RUN_MOTOR_IMAG:\n",
    "        return 1\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a483da1",
   "metadata": {},
   "source": [
    "### 1.5. Window Segmentation and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946d3bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_windows(data: np.ndarray, window_samples: int, overlap: float):\n",
    "    step = int(window_samples * (1 - overlap))\n",
    "    windows = []\n",
    "    for start in range(0, data.shape[1] - window_samples + 1, step):\n",
    "        windows.append(data[:, start:start + window_samples])\n",
    "    return np.asarray(windows)\n",
    "\n",
    "def normalize_windows(windows: np.ndarray):\n",
    "    mean = windows.mean(axis=2, keepdims=True)\n",
    "    std = windows.std(axis=2, keepdims=True) + 1e-8\n",
    "    return (windows - mean) / std\n",
    "\n",
    "def extract_rf_features(windows: np.ndarray):\n",
    "    means = windows.mean(axis=2)\n",
    "    stds = windows.std(axis=2)\n",
    "    rms = np.sqrt((windows**2).mean(axis=2))\n",
    "    energy = (windows**2).sum(axis=2)\n",
    "    return np.concatenate([means, stds, rms, energy], axis=1)\n",
    "\n",
    "def pick_motor_intervals_from_annotations(raw):\n",
    "    intervals = []\n",
    "    if raw.annotations is None or len(raw.annotations) == 0:\n",
    "        return intervals\n",
    "\n",
    "    for onset, duration, desc in zip(raw.annotations.onset, raw.annotations.duration, raw.annotations.description):\n",
    "        d = str(desc)\n",
    "        if d in {\"T1\", \"T2\"} and float(duration) > 0:\n",
    "            intervals.append((float(onset), float(onset + duration), d))\n",
    "    return intervals\n",
    "\n",
    "def windows_from_intervals(data: np.ndarray, sfreq: float, intervals, window_samples: int, overlap: float):\n",
    "    step = int(window_samples * (1 - overlap))\n",
    "    all_windows = []\n",
    "    meta = []\n",
    "\n",
    "    for (t0, t1, desc) in intervals:\n",
    "        start = int(round(t0 * sfreq))\n",
    "        end = int(round(t1 * sfreq))\n",
    "\n",
    "        if end - start < window_samples:\n",
    "            continue\n",
    "\n",
    "        for s in range(start, end - window_samples + 1, step):\n",
    "            all_windows.append(data[:, s:s + window_samples])\n",
    "            meta.append({\"desc\": desc, \"start_sample\": s, \"end_sample\": s + window_samples})\n",
    "\n",
    "    if not all_windows:\n",
    "        return np.empty((0, data.shape[0], window_samples), dtype=np.float32), []\n",
    "\n",
    "    return np.asarray(all_windows, dtype=np.float32), meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2764fa7",
   "metadata": {},
   "source": [
    "### 1.6. Segment recordings into fixed-length time windows, normalize signals, and select hand-related motor execution and imagery trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e516e1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cnn_list, y_list, X_rf_list, meta_rows = [], [], [], []\n",
    "\n",
    "n_channels_ref = None\n",
    "\n",
    "for edf_path in edf_paths:\n",
    "    edf_path = Path(edf_path)\n",
    "    run_id = run_id_from_filename(edf_path.name)\n",
    "    label = get_exec_imag_label(run_id)\n",
    "    if label == -1:\n",
    "        continue\n",
    "\n",
    "    raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n",
    "    raw.pick(\"eeg\")\n",
    "\n",
    "    if abs(raw.info[\"sfreq\"] - SFREQ) > 1e-3:\n",
    "        raw.resample(SFREQ)\n",
    "\n",
    "    data = raw.get_data()\n",
    "\n",
    "    if n_channels_ref is None:\n",
    "        n_channels_ref = data.shape[0]\n",
    "\n",
    "    if data.shape[0] != n_channels_ref:\n",
    "        if DEBUG:\n",
    "            print(f\"Skipping {edf_path.name}: channels {data.shape[0]} != {n_channels_ref}\")\n",
    "        continue\n",
    "\n",
    "    intervals = pick_motor_intervals_from_annotations(raw)  # T1/T2 only\n",
    "    if not intervals:\n",
    "        continue\n",
    "\n",
    "    windows, wmeta = windows_from_intervals(\n",
    "        data=data,\n",
    "        sfreq=raw.info[\"sfreq\"],\n",
    "        intervals=intervals,\n",
    "        window_samples=window_samples,\n",
    "        overlap=OVERLAP,\n",
    "    )\n",
    "    if windows.shape[0] == 0:\n",
    "        continue\n",
    "\n",
    "    windows = normalize_windows(windows).astype(np.float32)\n",
    "    feats = extract_rf_features(windows).astype(np.float32)\n",
    "\n",
    "    X_cnn_list.append(windows)\n",
    "    y_list.append(np.full((windows.shape[0],), label, dtype=np.int64))\n",
    "    X_rf_list.append(feats)\n",
    "\n",
    "    subject = edf_path.parent.name\n",
    "    for md in wmeta:\n",
    "        meta_rows.append({\n",
    "            \"subject\": subject,\n",
    "            \"run\": run_id,\n",
    "            \"exec_imag\": int(label),\n",
    "            \"trial_type\": md[\"desc\"], # T1/T2\n",
    "            \"start_sample\": md[\"start_sample\"],\n",
    "            \"end_sample\": md[\"end_sample\"],\n",
    "            \"edf\": str(edf_path),\n",
    "        })\n",
    "\n",
    "    if DEBUG:\n",
    "        print(f\"{edf_path.name}: intervals={len(intervals)} windows={windows.shape[0]} label={label}\")\n",
    "\n",
    "# stack\n",
    "if X_cnn_list:\n",
    "    X_cnn = np.vstack(X_cnn_list)\n",
    "    y = np.concatenate(y_list)\n",
    "    X_rf = np.vstack(X_rf_list)\n",
    "else:\n",
    "    X_cnn = np.empty((0, n_channels_ref or 64, window_samples), dtype=np.float32)\n",
    "    y = np.empty((0,), dtype=np.int64)\n",
    "    X_rf = np.empty((0, (n_channels_ref or 64) * 4), dtype=np.float32)\n",
    "\n",
    "meta = pd.DataFrame(meta_rows)\n",
    "\n",
    "print(\"X_cnn:\", X_cnn.shape)\n",
    "print(\"y:\", y.shape, \"counts:\", np.bincount(y) if y.size else \"empty\")\n",
    "print(\"X_rf:\", X_rf.shape)\n",
    "print(\"meta:\", meta.shape)\n",
    "\n",
    "# save\n",
    "np.save(os.path.join(OUTPUT_DIR, \"X_cnn.npy\"), X_cnn)\n",
    "np.save(os.path.join(OUTPUT_DIR, \"y.npy\"), y)\n",
    "np.save(os.path.join(OUTPUT_DIR, \"X_rf.npy\"), X_rf)\n",
    "meta.to_csv(os.path.join(OUTPUT_DIR, \"meta.csv\"), index=False)\n",
    "\n",
    "print(\"Saved to:\", OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edff042c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_mi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
